{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Concrete Strength Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBzmbgab17lM"
      },
      "source": [
        "# Assignment: Compresive Strength Concrete Problem\n",
        "\n",
        "\n",
        "### Abstract: \n",
        "\n",
        "Concrete is the most important material in civil engineering. The concrete compressive strength (concrete strength to bear the load) is a highly nonlinear function of age and ingredients.  <br><br>\n",
        "\n",
        "<table border=\"1\"  cellpadding=\"6\" bordercolor=\"red\">\n",
        "\t<tbody>\n",
        "        <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Multivariate</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">1030</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Physical</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\n",
        "    <tbody>\n",
        "        <tr>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n",
        "            <td><p class=\"normal\">Real</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n",
        "            <td><p class=\"normal\">9</p></td>\n",
        "            <td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n",
        "            <td><p class=\"normal\">2007-08-03</p></td>\n",
        "        </tr>\n",
        "     </tbody>\n",
        "    </table>\n",
        "<table border=\"1\" cellpadding=\"6\">\t\n",
        "    <tbody>\n",
        "    <tr>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">Regression</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n",
        "\t\t<td><p class=\"normal\">N/A</p></td>\n",
        "\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n",
        "\t\t<td><p class=\"normal\">231464</p></td>\n",
        "\t</tr>\n",
        "    </tbody>\n",
        "    </table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K_T02k017lg"
      },
      "source": [
        "###  Description:\n",
        "| Features Name | Data Type | Measurement | Description |\n",
        "| -- | -- | -- | -- |\n",
        "Cement (component 1) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Blast Furnace Slag (component 2) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Fly Ash (component 3) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Water (component 4) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Superplasticizer (component 5) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Coarse Aggregate (component 6) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Fine Aggregate (component 7) | quantitative | kg in a m3 mixture | Input Variable\n",
        "Age | quantitative | Day (1~365) | Input Variable\n",
        "Concrete compressive strength | quantitative | MPa | Output Variable\n",
        "\n",
        "### WORKFLOW :\n",
        "- Load Data\n",
        "- Check Missing Values ( If Exist ; Fill each record with mean of its feature )\n",
        "- Standardized the Input Variables. **Hint**: Centeralized the data\n",
        "- Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
        "- Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
        "- Compilation Step (Note : Its a Regression problem , select loss , metrics according to it)\n",
        "- Train the Model with Epochs (100) and validate it\n",
        "- If the model gets overfit tune your model by changing the units , No. of layers , activation function , epochs , add dropout layer or add Regularizer according to the need .\n",
        "- Evaluation Step\n",
        "- Prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZThwE-Vk17lh"
      },
      "source": [
        "# Load Data:\n",
        "[Click Here to Download DataSet](https://github.com/ramsha275/ML_Datasets/blob/main/compresive_strength_concrete.csv)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKvEL4L--gNg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb9j00ic17li"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epsvXquTBecv"
      },
      "source": [
        "# loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijRQB4Lpsn9v"
      },
      "source": [
        "dataset = pd.read_csv('./compresive_strength_concrete.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "hofrNGzW3DWz",
        "outputId": "d6a632b3-a697-4b26-a35d-45c06ec8507f"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
              "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
              "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
              "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
              "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
              "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
              "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
              "      <th>Age (day)</th>\n",
              "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>79.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>540.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1055.0</td>\n",
              "      <td>676.0</td>\n",
              "      <td>28</td>\n",
              "      <td>61.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>270</td>\n",
              "      <td>40.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>332.5</td>\n",
              "      <td>142.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>228.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>594.0</td>\n",
              "      <td>365</td>\n",
              "      <td>41.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198.6</td>\n",
              "      <td>132.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>978.4</td>\n",
              "      <td>825.5</td>\n",
              "      <td>360</td>\n",
              "      <td>44.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Cement (component 1)(kg in a m^3 mixture)  ...  Concrete compressive strength(MPa, megapascals) \n",
              "0                                      540.0  ...                                             79.99\n",
              "1                                      540.0  ...                                             61.89\n",
              "2                                      332.5  ...                                             40.27\n",
              "3                                      332.5  ...                                             41.05\n",
              "4                                      198.6  ...                                             44.30\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCViQFXa3Hdb"
      },
      "source": [
        "# checking null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adrSNhN43b74",
        "outputId": "ac4efde6-5516-47af-a329-d6b1ad143d94"
      },
      "source": [
        "dataset.isnull().values.any()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN02nZ_M4Dg_"
      },
      "source": [
        "dataset.columns = ['cement','blast furnace slag','fly ash','water','superplasticizer','coarse aggregagate','fine aggregate','age','concrete compressive strength']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cStVDPXA_JQh"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JldPuRJV4igX"
      },
      "source": [
        "# shuffling the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5PcPems3gIS"
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "dataset = shuffle(dataset)\n",
        "dataset.reset_index(inplace=True, drop=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF008H9V3krK"
      },
      "source": [
        "# splitting training, validation and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQoIGz6j5s6N"
      },
      "source": [
        "train_dataset = dataset[(dataset.index<np.percentile(dataset.index, 50))]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUBvME9k6xk9"
      },
      "source": [
        "validation_dataset = dataset[(dataset.index>np.percentile(dataset.index, 50)) & (dataset.index<=np.percentile(dataset.index, 70))]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7skccSuY7Joa"
      },
      "source": [
        "test_dataset = dataset[(dataset.index>np.percentile(dataset.index, 70))]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "7siePikG7-aJ",
        "outputId": "6606791f-0b90-45ad-afbe-0e10fc3ece1a"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cement</th>\n",
              "      <th>blast furnace slag</th>\n",
              "      <th>fly ash</th>\n",
              "      <th>water</th>\n",
              "      <th>superplasticizer</th>\n",
              "      <th>coarse aggregagate</th>\n",
              "      <th>fine aggregate</th>\n",
              "      <th>age</th>\n",
              "      <th>concrete compressive strength</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>148.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>839.0</td>\n",
              "      <td>884.0</td>\n",
              "      <td>28</td>\n",
              "      <td>15.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>389.9</td>\n",
              "      <td>189.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>145.9</td>\n",
              "      <td>22.0</td>\n",
              "      <td>944.7</td>\n",
              "      <td>755.8</td>\n",
              "      <td>28</td>\n",
              "      <td>74.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>135.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>166.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>961.0</td>\n",
              "      <td>805.0</td>\n",
              "      <td>28</td>\n",
              "      <td>13.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>349.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1056.0</td>\n",
              "      <td>809.0</td>\n",
              "      <td>3</td>\n",
              "      <td>15.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>236.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>192.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>972.6</td>\n",
              "      <td>749.1</td>\n",
              "      <td>7</td>\n",
              "      <td>20.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>213.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>174.2</td>\n",
              "      <td>154.6</td>\n",
              "      <td>11.7</td>\n",
              "      <td>1052.3</td>\n",
              "      <td>775.5</td>\n",
              "      <td>56</td>\n",
              "      <td>51.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>350.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>203.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>974.0</td>\n",
              "      <td>775.0</td>\n",
              "      <td>180</td>\n",
              "      <td>32.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>147.8</td>\n",
              "      <td>175.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>171.2</td>\n",
              "      <td>2.2</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>828.5</td>\n",
              "      <td>28</td>\n",
              "      <td>26.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>183.9</td>\n",
              "      <td>122.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>203.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>959.2</td>\n",
              "      <td>800.0</td>\n",
              "      <td>3</td>\n",
              "      <td>4.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>166.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163.3</td>\n",
              "      <td>176.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1058.6</td>\n",
              "      <td>780.1</td>\n",
              "      <td>14</td>\n",
              "      <td>25.48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     cement  blast furnace slag  ...  age  concrete compressive strength\n",
              "0     148.0                 0.0  ...   28                          15.52\n",
              "1     389.9               189.0  ...   28                          74.50\n",
              "2     135.0                 0.0  ...   28                          13.29\n",
              "3     349.0                 0.0  ...    3                          15.87\n",
              "4     236.0               157.0  ...    7                          20.42\n",
              "..      ...                 ...  ...  ...                            ...\n",
              "510   213.5                 0.0  ...   56                          51.43\n",
              "511   350.0                 0.0  ...  180                          32.72\n",
              "512   147.8               175.1  ...   28                          26.92\n",
              "513   183.9               122.6  ...    3                           4.90\n",
              "514   166.1                 0.0  ...   14                          25.48\n",
              "\n",
              "[515 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lL5JCUG9sn9x"
      },
      "source": [
        "\n",
        "\n",
        "# training data and labels\n",
        "x_train = train_dataset.drop(columns='concrete compressive strength')\n",
        "y_train = train_dataset.loc[:, 'concrete compressive strength']\n",
        "\n",
        "# validation data and labels\n",
        "x_val = validation_dataset.drop(columns='concrete compressive strength')\n",
        "y_val = validation_dataset.loc[:, 'concrete compressive strength']\n",
        "\n",
        "# test data and labels\n",
        "x_test = test_dataset.drop(columns='concrete compressive strength')\n",
        "y_test = test_dataset.loc[:, 'concrete compressive strength']\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL4ZYuUD89Y9"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaGDLZ2_AAfP"
      },
      "source": [
        "# Normalizing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVcB5FuDxn-B"
      },
      "source": [
        "# taking the mean and std of data\n",
        "\n",
        "mean_data = x_train.mean(axis=0)\n",
        "std_data = x_train.std(axis=0)\n",
        "\n",
        "# applying mean and std on training data\n",
        "\n",
        "x_train-= mean_data\n",
        "x_train /= std_data\n",
        "\n",
        "# applying mean and std on validation data\n",
        "x_val -= mean_data\n",
        "x_val /= std_data\n",
        "\n",
        "# applying mean and std on testing data\n",
        "x_test -= mean_data\n",
        "x_test /= std_data\n",
        "\n",
        "\n",
        "# taking the mean and std of labels\n",
        "mean_labels = y_train.mean(axis=0)\n",
        "std_labels  = y_train.std(axis=0)\n",
        "\n",
        "# applying mean and std on training, validation and testing labels\n",
        "y_train -= mean_labels\n",
        "y_train /= std_labels\n",
        "\n",
        "y_val -= mean_labels\n",
        "y_val /=std_labels\n",
        "\n",
        "y_test -= mean_labels\n",
        "y_test /= std_labels\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zue00I_uADDF"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab4VdV-CTs23"
      },
      "source": [
        "# converting to np array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q83_9OJ_GoJZ"
      },
      "source": [
        "train_data = np.array(x_train.iloc[:])\n",
        "validation_data = np.array(x_val.iloc[:])\n",
        "test_data = np.array(x_test.iloc[:])\n",
        "\n",
        "train_labels = np.array(y_train.astype('float32'))\n",
        "validation_labels = np.array(y_val.astype(('float32')))\n",
        "test_labels = np.array(y_test.astype('float32'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35XAOX6mDehB"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kznbWJnwTx-8"
      },
      "source": [
        "# building model with regulizers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzZlQ-Jiox3l"
      },
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "def build_model():\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Dense(8, kernel_regularizer=regularizers.l2(0.001),activation='relu',input_shape=(train_data.shape[1],)))\n",
        "  model.add(layers.Dense(6, kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
        "  model.add(layers.Dense(4, kernel_regularizer=regularizers.l2(0.001),activation='relu'))\n",
        "  model.add(layers.Dense(1))\n",
        "  model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2a2OxiqLJTF",
        "outputId": "316be286-e0d9-43ef-da4c-6fb89dd4de66"
      },
      "source": [
        "build_model()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fc195d01f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5W9P82tLLO-"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyxqweOsT6-C"
      },
      "source": [
        "# training and validating the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-naIDVIDLXMF",
        "outputId": "9b4095b3-85ca-4f31-f0ab-cdd0322fe223"
      },
      "source": [
        "history = model.fit(train_data,\n",
        "train_labels,\n",
        "epochs=150,\n",
        "batch_size=128,\n",
        "validation_data=(validation_data, validation_labels))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "5/5 [==============================] - 1s 125ms/step - loss: 1.2869 - mae: 0.8899 - val_loss: 1.1446 - val_mae: 0.8704\n",
            "Epoch 2/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1516 - mae: 0.8359 - val_loss: 1.1064 - val_mae: 0.8550\n",
            "Epoch 3/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.1325 - mae: 0.8367 - val_loss: 1.0664 - val_mae: 0.8400\n",
            "Epoch 4/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 1.0516 - mae: 0.7980 - val_loss: 1.0425 - val_mae: 0.8317\n",
            "Epoch 5/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 1.1274 - mae: 0.8343 - val_loss: 1.0217 - val_mae: 0.8240\n",
            "Epoch 6/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 1.0252 - mae: 0.8041 - val_loss: 1.0000 - val_mae: 0.8164\n",
            "Epoch 7/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.9821 - mae: 0.7717 - val_loss: 0.9798 - val_mae: 0.8080\n",
            "Epoch 8/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.9363 - mae: 0.7592 - val_loss: 0.9659 - val_mae: 0.8028\n",
            "Epoch 9/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.9832 - mae: 0.7786 - val_loss: 0.9510 - val_mae: 0.7970\n",
            "Epoch 10/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.9039 - mae: 0.7471 - val_loss: 0.9397 - val_mae: 0.7915\n",
            "Epoch 11/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9293 - mae: 0.7567 - val_loss: 0.9296 - val_mae: 0.7870\n",
            "Epoch 12/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9451 - mae: 0.7733 - val_loss: 0.9215 - val_mae: 0.7830\n",
            "Epoch 13/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8929 - mae: 0.7401 - val_loss: 0.9129 - val_mae: 0.7795\n",
            "Epoch 14/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.9147 - mae: 0.7567 - val_loss: 0.9074 - val_mae: 0.7768\n",
            "Epoch 15/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8948 - mae: 0.7504 - val_loss: 0.8993 - val_mae: 0.7736\n",
            "Epoch 16/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8857 - mae: 0.7504 - val_loss: 0.8911 - val_mae: 0.7698\n",
            "Epoch 17/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8506 - mae: 0.7252 - val_loss: 0.8838 - val_mae: 0.7670\n",
            "Epoch 18/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8528 - mae: 0.7328 - val_loss: 0.8754 - val_mae: 0.7634\n",
            "Epoch 19/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8819 - mae: 0.7428 - val_loss: 0.8656 - val_mae: 0.7589\n",
            "Epoch 20/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8048 - mae: 0.7122 - val_loss: 0.8569 - val_mae: 0.7552\n",
            "Epoch 21/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8578 - mae: 0.7329 - val_loss: 0.8477 - val_mae: 0.7512\n",
            "Epoch 22/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.8034 - mae: 0.7054 - val_loss: 0.8376 - val_mae: 0.7459\n",
            "Epoch 23/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8462 - mae: 0.7273 - val_loss: 0.8276 - val_mae: 0.7410\n",
            "Epoch 24/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.8204 - mae: 0.7180 - val_loss: 0.8153 - val_mae: 0.7348\n",
            "Epoch 25/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8310 - mae: 0.7193 - val_loss: 0.8061 - val_mae: 0.7304\n",
            "Epoch 26/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8278 - mae: 0.7103 - val_loss: 0.7953 - val_mae: 0.7253\n",
            "Epoch 27/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.8060 - mae: 0.7126 - val_loss: 0.7880 - val_mae: 0.7220\n",
            "Epoch 28/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7808 - mae: 0.6978 - val_loss: 0.7767 - val_mae: 0.7159\n",
            "Epoch 29/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7723 - mae: 0.6979 - val_loss: 0.7669 - val_mae: 0.7110\n",
            "Epoch 30/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7634 - mae: 0.6960 - val_loss: 0.7493 - val_mae: 0.7020\n",
            "Epoch 31/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7504 - mae: 0.6874 - val_loss: 0.7399 - val_mae: 0.6975\n",
            "Epoch 32/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7755 - mae: 0.6988 - val_loss: 0.7294 - val_mae: 0.6920\n",
            "Epoch 33/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.7292 - mae: 0.6792 - val_loss: 0.7185 - val_mae: 0.6866\n",
            "Epoch 34/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6917 - mae: 0.6589 - val_loss: 0.7080 - val_mae: 0.6799\n",
            "Epoch 35/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.7257 - mae: 0.6666 - val_loss: 0.6982 - val_mae: 0.6746\n",
            "Epoch 36/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.7002 - mae: 0.6566 - val_loss: 0.6895 - val_mae: 0.6707\n",
            "Epoch 37/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6721 - mae: 0.6396 - val_loss: 0.6776 - val_mae: 0.6655\n",
            "Epoch 38/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6789 - mae: 0.6517 - val_loss: 0.6714 - val_mae: 0.6616\n",
            "Epoch 39/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6638 - mae: 0.6452 - val_loss: 0.6645 - val_mae: 0.6586\n",
            "Epoch 40/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6353 - mae: 0.6215 - val_loss: 0.6606 - val_mae: 0.6559\n",
            "Epoch 41/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6908 - mae: 0.6541 - val_loss: 0.6534 - val_mae: 0.6521\n",
            "Epoch 42/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6775 - mae: 0.6427 - val_loss: 0.6450 - val_mae: 0.6452\n",
            "Epoch 43/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6389 - mae: 0.6241 - val_loss: 0.6395 - val_mae: 0.6429\n",
            "Epoch 44/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6326 - mae: 0.6240 - val_loss: 0.6328 - val_mae: 0.6389\n",
            "Epoch 45/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6031 - mae: 0.6049 - val_loss: 0.6261 - val_mae: 0.6357\n",
            "Epoch 46/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6126 - mae: 0.6141 - val_loss: 0.6147 - val_mae: 0.6282\n",
            "Epoch 47/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6472 - mae: 0.6349 - val_loss: 0.6118 - val_mae: 0.6290\n",
            "Epoch 48/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6014 - mae: 0.6095 - val_loss: 0.6090 - val_mae: 0.6275\n",
            "Epoch 49/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6317 - mae: 0.6279 - val_loss: 0.6024 - val_mae: 0.6226\n",
            "Epoch 50/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.6065 - mae: 0.6061 - val_loss: 0.5968 - val_mae: 0.6191\n",
            "Epoch 51/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5983 - mae: 0.6083 - val_loss: 0.5908 - val_mae: 0.6150\n",
            "Epoch 52/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6046 - mae: 0.6064 - val_loss: 0.5885 - val_mae: 0.6150\n",
            "Epoch 53/150\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.5768 - mae: 0.5931 - val_loss: 0.5826 - val_mae: 0.6110\n",
            "Epoch 54/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5824 - mae: 0.5949 - val_loss: 0.5772 - val_mae: 0.6080\n",
            "Epoch 55/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.6053 - mae: 0.6068 - val_loss: 0.5723 - val_mae: 0.6048\n",
            "Epoch 56/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5477 - mae: 0.5721 - val_loss: 0.5623 - val_mae: 0.5992\n",
            "Epoch 57/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5807 - mae: 0.5914 - val_loss: 0.5583 - val_mae: 0.5970\n",
            "Epoch 58/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5601 - mae: 0.5832 - val_loss: 0.5533 - val_mae: 0.5963\n",
            "Epoch 59/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.5642 - mae: 0.5876 - val_loss: 0.5474 - val_mae: 0.5918\n",
            "Epoch 60/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5523 - mae: 0.5809 - val_loss: 0.5413 - val_mae: 0.5879\n",
            "Epoch 61/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5376 - mae: 0.5657 - val_loss: 0.5358 - val_mae: 0.5855\n",
            "Epoch 62/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5355 - mae: 0.5694 - val_loss: 0.5328 - val_mae: 0.5846\n",
            "Epoch 63/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5190 - mae: 0.5549 - val_loss: 0.5270 - val_mae: 0.5806\n",
            "Epoch 64/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.5506 - mae: 0.5731 - val_loss: 0.5225 - val_mae: 0.5790\n",
            "Epoch 65/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5231 - mae: 0.5613 - val_loss: 0.5169 - val_mae: 0.5755\n",
            "Epoch 66/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5095 - mae: 0.5563 - val_loss: 0.5083 - val_mae: 0.5705\n",
            "Epoch 67/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4960 - mae: 0.5401 - val_loss: 0.4997 - val_mae: 0.5652\n",
            "Epoch 68/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.5217 - mae: 0.5574 - val_loss: 0.4945 - val_mae: 0.5620\n",
            "Epoch 69/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4977 - mae: 0.5474 - val_loss: 0.4916 - val_mae: 0.5598\n",
            "Epoch 70/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4958 - mae: 0.5461 - val_loss: 0.4877 - val_mae: 0.5569\n",
            "Epoch 71/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5305 - mae: 0.5624 - val_loss: 0.4833 - val_mae: 0.5536\n",
            "Epoch 72/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4868 - mae: 0.5373 - val_loss: 0.4798 - val_mae: 0.5527\n",
            "Epoch 73/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4987 - mae: 0.5411 - val_loss: 0.4766 - val_mae: 0.5504\n",
            "Epoch 74/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4771 - mae: 0.5289 - val_loss: 0.4735 - val_mae: 0.5494\n",
            "Epoch 75/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.5031 - mae: 0.5509 - val_loss: 0.4719 - val_mae: 0.5471\n",
            "Epoch 76/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4698 - mae: 0.5281 - val_loss: 0.4690 - val_mae: 0.5459\n",
            "Epoch 77/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4604 - mae: 0.5250 - val_loss: 0.4662 - val_mae: 0.5448\n",
            "Epoch 78/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4687 - mae: 0.5297 - val_loss: 0.4637 - val_mae: 0.5435\n",
            "Epoch 79/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4716 - mae: 0.5273 - val_loss: 0.4559 - val_mae: 0.5384\n",
            "Epoch 80/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4759 - mae: 0.5302 - val_loss: 0.4522 - val_mae: 0.5345\n",
            "Epoch 81/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4631 - mae: 0.5161 - val_loss: 0.4494 - val_mae: 0.5323\n",
            "Epoch 82/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4561 - mae: 0.5168 - val_loss: 0.4448 - val_mae: 0.5291\n",
            "Epoch 83/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4528 - mae: 0.5152 - val_loss: 0.4451 - val_mae: 0.5294\n",
            "Epoch 84/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4467 - mae: 0.5160 - val_loss: 0.4399 - val_mae: 0.5252\n",
            "Epoch 85/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4498 - mae: 0.5140 - val_loss: 0.4377 - val_mae: 0.5243\n",
            "Epoch 86/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4329 - mae: 0.5027 - val_loss: 0.4353 - val_mae: 0.5215\n",
            "Epoch 87/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4464 - mae: 0.5122 - val_loss: 0.4317 - val_mae: 0.5176\n",
            "Epoch 88/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4381 - mae: 0.5005 - val_loss: 0.4282 - val_mae: 0.5140\n",
            "Epoch 89/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4307 - mae: 0.4975 - val_loss: 0.4226 - val_mae: 0.5080\n",
            "Epoch 90/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.4020 - mae: 0.4766 - val_loss: 0.4228 - val_mae: 0.5098\n",
            "Epoch 91/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4122 - mae: 0.4854 - val_loss: 0.4209 - val_mae: 0.5077\n",
            "Epoch 92/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4276 - mae: 0.4914 - val_loss: 0.4192 - val_mae: 0.5050\n",
            "Epoch 93/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.4476 - mae: 0.5041 - val_loss: 0.4175 - val_mae: 0.5044\n",
            "Epoch 94/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4206 - mae: 0.4871 - val_loss: 0.4150 - val_mae: 0.5040\n",
            "Epoch 95/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3964 - mae: 0.4745 - val_loss: 0.4131 - val_mae: 0.5030\n",
            "Epoch 96/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3958 - mae: 0.4760 - val_loss: 0.4138 - val_mae: 0.5047\n",
            "Epoch 97/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3803 - mae: 0.4702 - val_loss: 0.4077 - val_mae: 0.4983\n",
            "Epoch 98/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3988 - mae: 0.4721 - val_loss: 0.4068 - val_mae: 0.4978\n",
            "Epoch 99/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4008 - mae: 0.4748 - val_loss: 0.4050 - val_mae: 0.4960\n",
            "Epoch 100/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3883 - mae: 0.4700 - val_loss: 0.4008 - val_mae: 0.4926\n",
            "Epoch 101/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3778 - mae: 0.4568 - val_loss: 0.3983 - val_mae: 0.4891\n",
            "Epoch 102/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3881 - mae: 0.4600 - val_loss: 0.3970 - val_mae: 0.4836\n",
            "Epoch 103/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3816 - mae: 0.4548 - val_loss: 0.3962 - val_mae: 0.4807\n",
            "Epoch 104/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3995 - mae: 0.4615 - val_loss: 0.3938 - val_mae: 0.4807\n",
            "Epoch 105/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3824 - mae: 0.4614 - val_loss: 0.3920 - val_mae: 0.4812\n",
            "Epoch 106/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3786 - mae: 0.4493 - val_loss: 0.3898 - val_mae: 0.4758\n",
            "Epoch 107/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3552 - mae: 0.4338 - val_loss: 0.3871 - val_mae: 0.4736\n",
            "Epoch 108/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3800 - mae: 0.4505 - val_loss: 0.3856 - val_mae: 0.4745\n",
            "Epoch 109/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3808 - mae: 0.4519 - val_loss: 0.3860 - val_mae: 0.4785\n",
            "Epoch 110/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3411 - mae: 0.4298 - val_loss: 0.3834 - val_mae: 0.4749\n",
            "Epoch 111/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.3638 - mae: 0.4423 - val_loss: 0.3810 - val_mae: 0.4677\n",
            "Epoch 112/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3286 - mae: 0.4142 - val_loss: 0.3796 - val_mae: 0.4671\n",
            "Epoch 113/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3548 - mae: 0.4327 - val_loss: 0.3787 - val_mae: 0.4650\n",
            "Epoch 114/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3250 - mae: 0.4116 - val_loss: 0.3760 - val_mae: 0.4667\n",
            "Epoch 115/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3425 - mae: 0.4291 - val_loss: 0.3754 - val_mae: 0.4679\n",
            "Epoch 116/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3410 - mae: 0.4241 - val_loss: 0.3732 - val_mae: 0.4677\n",
            "Epoch 117/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3465 - mae: 0.4337 - val_loss: 0.3709 - val_mae: 0.4651\n",
            "Epoch 118/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3312 - mae: 0.4161 - val_loss: 0.3689 - val_mae: 0.4620\n",
            "Epoch 119/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3318 - mae: 0.4205 - val_loss: 0.3688 - val_mae: 0.4619\n",
            "Epoch 120/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3286 - mae: 0.4182 - val_loss: 0.3682 - val_mae: 0.4612\n",
            "Epoch 121/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3471 - mae: 0.4243 - val_loss: 0.3634 - val_mae: 0.4551\n",
            "Epoch 122/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3353 - mae: 0.4205 - val_loss: 0.3615 - val_mae: 0.4543\n",
            "Epoch 123/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.3284 - mae: 0.4127 - val_loss: 0.3596 - val_mae: 0.4545\n",
            "Epoch 124/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3412 - mae: 0.4257 - val_loss: 0.3595 - val_mae: 0.4492\n",
            "Epoch 125/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3145 - mae: 0.4056 - val_loss: 0.3585 - val_mae: 0.4518\n",
            "Epoch 126/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3208 - mae: 0.4102 - val_loss: 0.3563 - val_mae: 0.4480\n",
            "Epoch 127/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3112 - mae: 0.3957 - val_loss: 0.3536 - val_mae: 0.4484\n",
            "Epoch 128/150\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3399 - mae: 0.4178 - val_loss: 0.3500 - val_mae: 0.4473\n",
            "Epoch 129/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3214 - mae: 0.4132 - val_loss: 0.3486 - val_mae: 0.4482\n",
            "Epoch 130/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2995 - mae: 0.4024 - val_loss: 0.3455 - val_mae: 0.4400\n",
            "Epoch 131/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2894 - mae: 0.3883 - val_loss: 0.3436 - val_mae: 0.4407\n",
            "Epoch 132/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3075 - mae: 0.4017 - val_loss: 0.3416 - val_mae: 0.4388\n",
            "Epoch 133/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2975 - mae: 0.3913 - val_loss: 0.3393 - val_mae: 0.4351\n",
            "Epoch 134/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2951 - mae: 0.3883 - val_loss: 0.3366 - val_mae: 0.4352\n",
            "Epoch 135/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3168 - mae: 0.4094 - val_loss: 0.3318 - val_mae: 0.4304\n",
            "Epoch 136/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2874 - mae: 0.3821 - val_loss: 0.3283 - val_mae: 0.4292\n",
            "Epoch 137/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2911 - mae: 0.3926 - val_loss: 0.3261 - val_mae: 0.4248\n",
            "Epoch 138/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2896 - mae: 0.3911 - val_loss: 0.3235 - val_mae: 0.4239\n",
            "Epoch 139/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2797 - mae: 0.3840 - val_loss: 0.3223 - val_mae: 0.4223\n",
            "Epoch 140/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2925 - mae: 0.3905 - val_loss: 0.3215 - val_mae: 0.4263\n",
            "Epoch 141/150\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2997 - mae: 0.3962 - val_loss: 0.3174 - val_mae: 0.4212\n",
            "Epoch 142/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2825 - mae: 0.3811 - val_loss: 0.3171 - val_mae: 0.4221\n",
            "Epoch 143/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2900 - mae: 0.3890 - val_loss: 0.3168 - val_mae: 0.4203\n",
            "Epoch 144/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2880 - mae: 0.3936 - val_loss: 0.3155 - val_mae: 0.4154\n",
            "Epoch 145/150\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2807 - mae: 0.3839 - val_loss: 0.3147 - val_mae: 0.4129\n",
            "Epoch 146/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2738 - mae: 0.3766 - val_loss: 0.3110 - val_mae: 0.4088\n",
            "Epoch 147/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2782 - mae: 0.3816 - val_loss: 0.3127 - val_mae: 0.4077\n",
            "Epoch 148/150\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2799 - mae: 0.3735 - val_loss: 0.3078 - val_mae: 0.4070\n",
            "Epoch 149/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2572 - mae: 0.3644 - val_loss: 0.3064 - val_mae: 0.4120\n",
            "Epoch 150/150\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2799 - mae: 0.3860 - val_loss: 0.3031 - val_mae: 0.4076\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFfyPNa0Lj24",
        "outputId": "daa348b2-ca6a-48ed-96ff-10e5f283a525"
      },
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Y8xEKSA-MUl5",
        "outputId": "379dae82-dc78-4f26-dd1f-1b1abdb0457e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W50VLo6NMgAB"
      },
      "source": [
        "training_data = np.concatenate([train_data, validation_data])\n",
        "training_labels = np.concatenate([train_labels, validation_labels])\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmr4JeTena4J",
        "outputId": "42e1e989-7ac3-49e5-c11d-42bbcd8c224a"
      },
      "source": [
        "model.fit(training_data, training_labels,\n",
        "epochs=150, batch_size=16, verbose=1)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_labels)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2735 - mae: 0.3825\n",
            "Epoch 2/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2636 - mae: 0.3772\n",
            "Epoch 3/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2538 - mae: 0.3679\n",
            "Epoch 4/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2451 - mae: 0.3640\n",
            "Epoch 5/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2376 - mae: 0.3580\n",
            "Epoch 6/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2299 - mae: 0.3512\n",
            "Epoch 7/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2241 - mae: 0.3469\n",
            "Epoch 8/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2171 - mae: 0.3424\n",
            "Epoch 9/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2128 - mae: 0.3392\n",
            "Epoch 10/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2091 - mae: 0.3347\n",
            "Epoch 11/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.2047 - mae: 0.3332\n",
            "Epoch 12/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1997 - mae: 0.3297\n",
            "Epoch 13/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1963 - mae: 0.3267\n",
            "Epoch 14/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1926 - mae: 0.3206\n",
            "Epoch 15/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1891 - mae: 0.3199\n",
            "Epoch 16/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1870 - mae: 0.3172\n",
            "Epoch 17/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1849 - mae: 0.3151\n",
            "Epoch 18/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1823 - mae: 0.3120\n",
            "Epoch 19/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1802 - mae: 0.3109\n",
            "Epoch 20/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1785 - mae: 0.3086\n",
            "Epoch 21/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1765 - mae: 0.3063\n",
            "Epoch 22/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1754 - mae: 0.3053\n",
            "Epoch 23/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1739 - mae: 0.3047\n",
            "Epoch 24/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1725 - mae: 0.3027\n",
            "Epoch 25/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1709 - mae: 0.3007\n",
            "Epoch 26/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1693 - mae: 0.2991\n",
            "Epoch 27/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1700 - mae: 0.2994\n",
            "Epoch 28/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1664 - mae: 0.2964\n",
            "Epoch 29/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1681 - mae: 0.2973\n",
            "Epoch 30/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1654 - mae: 0.2939\n",
            "Epoch 31/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1648 - mae: 0.2929\n",
            "Epoch 32/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1648 - mae: 0.2926\n",
            "Epoch 33/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1631 - mae: 0.2912\n",
            "Epoch 34/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1621 - mae: 0.2907\n",
            "Epoch 35/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1610 - mae: 0.2909\n",
            "Epoch 36/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1602 - mae: 0.2879\n",
            "Epoch 37/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1557 - mae: 0.2852\n",
            "Epoch 38/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1583 - mae: 0.2879\n",
            "Epoch 39/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1575 - mae: 0.2857\n",
            "Epoch 40/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1574 - mae: 0.2849\n",
            "Epoch 41/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1571 - mae: 0.2845\n",
            "Epoch 42/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1549 - mae: 0.2827\n",
            "Epoch 43/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1553 - mae: 0.2830\n",
            "Epoch 44/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1541 - mae: 0.2816\n",
            "Epoch 45/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1529 - mae: 0.2820\n",
            "Epoch 46/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1535 - mae: 0.2808\n",
            "Epoch 47/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1519 - mae: 0.2780\n",
            "Epoch 48/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1526 - mae: 0.2800\n",
            "Epoch 49/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1523 - mae: 0.2794\n",
            "Epoch 50/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1507 - mae: 0.2766\n",
            "Epoch 51/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1513 - mae: 0.2790\n",
            "Epoch 52/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1508 - mae: 0.2775\n",
            "Epoch 53/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1500 - mae: 0.2756\n",
            "Epoch 54/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1497 - mae: 0.2767\n",
            "Epoch 55/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1493 - mae: 0.2774\n",
            "Epoch 56/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1478 - mae: 0.2727\n",
            "Epoch 57/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1486 - mae: 0.2728\n",
            "Epoch 58/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1472 - mae: 0.2718\n",
            "Epoch 59/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1465 - mae: 0.2722\n",
            "Epoch 60/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1451 - mae: 0.2701\n",
            "Epoch 61/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1459 - mae: 0.2705\n",
            "Epoch 62/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1445 - mae: 0.2704\n",
            "Epoch 63/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1447 - mae: 0.2681\n",
            "Epoch 64/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1436 - mae: 0.2669\n",
            "Epoch 65/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1438 - mae: 0.2683\n",
            "Epoch 66/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1418 - mae: 0.2662\n",
            "Epoch 67/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1428 - mae: 0.2669\n",
            "Epoch 68/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1429 - mae: 0.2659\n",
            "Epoch 69/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1397 - mae: 0.2624\n",
            "Epoch 70/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1413 - mae: 0.2644\n",
            "Epoch 71/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1410 - mae: 0.2638\n",
            "Epoch 72/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1396 - mae: 0.2632\n",
            "Epoch 73/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1394 - mae: 0.2635\n",
            "Epoch 74/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1399 - mae: 0.2622\n",
            "Epoch 75/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1387 - mae: 0.2621\n",
            "Epoch 76/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1380 - mae: 0.2593\n",
            "Epoch 77/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1388 - mae: 0.2626\n",
            "Epoch 78/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1384 - mae: 0.2617\n",
            "Epoch 79/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1378 - mae: 0.2585\n",
            "Epoch 80/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1379 - mae: 0.2585\n",
            "Epoch 81/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1378 - mae: 0.2605\n",
            "Epoch 82/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1375 - mae: 0.2606\n",
            "Epoch 83/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1351 - mae: 0.2571\n",
            "Epoch 84/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1362 - mae: 0.2575\n",
            "Epoch 85/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1360 - mae: 0.2590\n",
            "Epoch 86/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1353 - mae: 0.2562\n",
            "Epoch 87/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1346 - mae: 0.2564\n",
            "Epoch 88/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1351 - mae: 0.2593\n",
            "Epoch 89/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1335 - mae: 0.2546\n",
            "Epoch 90/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1346 - mae: 0.2565\n",
            "Epoch 91/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1338 - mae: 0.2551\n",
            "Epoch 92/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1337 - mae: 0.2548\n",
            "Epoch 93/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1329 - mae: 0.2546\n",
            "Epoch 94/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1332 - mae: 0.2552\n",
            "Epoch 95/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1333 - mae: 0.2545\n",
            "Epoch 96/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1332 - mae: 0.2553\n",
            "Epoch 97/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1316 - mae: 0.2566\n",
            "Epoch 98/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1329 - mae: 0.2551\n",
            "Epoch 99/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1315 - mae: 0.2544\n",
            "Epoch 100/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1315 - mae: 0.2539\n",
            "Epoch 101/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1311 - mae: 0.2548\n",
            "Epoch 102/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1310 - mae: 0.2529\n",
            "Epoch 103/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1305 - mae: 0.2514\n",
            "Epoch 104/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1307 - mae: 0.2529\n",
            "Epoch 105/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1292 - mae: 0.2504\n",
            "Epoch 106/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1303 - mae: 0.2516\n",
            "Epoch 107/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1296 - mae: 0.2499\n",
            "Epoch 108/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1295 - mae: 0.2499\n",
            "Epoch 109/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1282 - mae: 0.2501\n",
            "Epoch 110/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1279 - mae: 0.2482\n",
            "Epoch 111/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1280 - mae: 0.2476\n",
            "Epoch 112/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1275 - mae: 0.2491\n",
            "Epoch 113/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1268 - mae: 0.2483\n",
            "Epoch 114/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1261 - mae: 0.2468\n",
            "Epoch 115/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1258 - mae: 0.2452\n",
            "Epoch 116/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1262 - mae: 0.2455\n",
            "Epoch 117/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1255 - mae: 0.2468\n",
            "Epoch 118/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1257 - mae: 0.2459\n",
            "Epoch 119/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1253 - mae: 0.2458\n",
            "Epoch 120/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1247 - mae: 0.2448\n",
            "Epoch 121/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1237 - mae: 0.2437\n",
            "Epoch 122/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1243 - mae: 0.2446\n",
            "Epoch 123/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1237 - mae: 0.2439\n",
            "Epoch 124/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1232 - mae: 0.2436\n",
            "Epoch 125/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1234 - mae: 0.2408\n",
            "Epoch 126/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1227 - mae: 0.2420\n",
            "Epoch 127/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1227 - mae: 0.2407\n",
            "Epoch 128/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1235 - mae: 0.2432\n",
            "Epoch 129/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1218 - mae: 0.2415\n",
            "Epoch 130/150\n",
            "46/46 [==============================] - 0s 2ms/step - loss: 0.1212 - mae: 0.2416\n",
            "Epoch 131/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1206 - mae: 0.2400\n",
            "Epoch 132/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1201 - mae: 0.2406\n",
            "Epoch 133/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1211 - mae: 0.2406\n",
            "Epoch 134/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1211 - mae: 0.2414\n",
            "Epoch 135/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1216 - mae: 0.2413\n",
            "Epoch 136/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1219 - mae: 0.2405\n",
            "Epoch 137/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1206 - mae: 0.2417\n",
            "Epoch 138/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1200 - mae: 0.2393\n",
            "Epoch 139/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1192 - mae: 0.2379\n",
            "Epoch 140/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1203 - mae: 0.2386\n",
            "Epoch 141/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1200 - mae: 0.2388\n",
            "Epoch 142/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1201 - mae: 0.2380\n",
            "Epoch 143/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1189 - mae: 0.2378\n",
            "Epoch 144/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1194 - mae: 0.2400\n",
            "Epoch 145/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1192 - mae: 0.2374\n",
            "Epoch 146/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1189 - mae: 0.2368\n",
            "Epoch 147/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1188 - mae: 0.2375\n",
            "Epoch 148/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1180 - mae: 0.2366\n",
            "Epoch 149/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1188 - mae: 0.2374\n",
            "Epoch 150/150\n",
            "46/46 [==============================] - 0s 1ms/step - loss: 0.1177 - mae: 0.2352\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 0.1366 - mae: 0.2549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-NSngeLRUT0",
        "outputId": "617de0b2-9341-4bd4-cec3-e6d06b91d164"
      },
      "source": [
        "test_mae_score"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2548525929450989"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8Z1kkB_RiOT",
        "outputId": "de5d9b36-275d-4dfc-af07-8875fbb40392"
      },
      "source": [
        "test_labels[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.5360518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYLzf_akRzVE"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiDUDeFe-Czu"
      },
      "source": [
        "prediction = model.predict(test_data[0].reshape(1, 8))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXWoRbmDR9lH",
        "outputId": "3335392f-89ea-4848-9484-9215cffd4184"
      },
      "source": [
        "prediction"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.5780847]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759qp5VdR_Cf"
      },
      "source": [
        ""
      ],
      "execution_count": 27,
      "outputs": []
    }
  ]
}